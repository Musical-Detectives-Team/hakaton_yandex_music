{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da42bf38",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e11ad",
   "metadata": {},
   "source": [
    "Импортируем библиотеки и прописываем пути, устанавливаем random_state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fad77bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63b778e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COVERS = 'data/raw/covers.json'\n",
    "PATH_LYRICS = 'data/raw/lyrics.json'\n",
    "PATH_META = 'data/raw/meta.json'\n",
    "\n",
    "RANDOM_STATE = 54321"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc9548b",
   "metadata": {},
   "source": [
    "Напишем функцию, которая на вход будет принимать пути к нашим датасетам, проводить чистку данных и возвращать объединённый датасет. Также будем использовать функцию написанную в EDA, для частичного восстановления языка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bafc8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(correct_simb: str, text: str) -> str:\n",
    "    new_text = re.sub(correct_simb, ' ', text)    \n",
    "    new_text = new_text.split()\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2d0b505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_united_df(path_covers: str, psth_lyrics: str, path_meta: str) -> pd.DataFrame:\n",
    "    df_covers = pd.read_json(PATH_COVERS, lines=True)\n",
    "    df_lyrics = pd.read_json(PATH_LYRICS, lines=True)\n",
    "    df_meta = pd.read_json(PATH_META, lines=True, convert_dates=['dttm'])\n",
    "    \n",
    "    df_covers = df_covers.dropna()\n",
    "    df_lyrics = df_lyrics.drop_duplicates(subset='track_id')\n",
    "    df_meta = df_meta[df_meta['duration']!=0]\n",
    "    \n",
    "    df_union = (df_covers.merge(df_lyrics, on = 'track_id', how = 'inner')\n",
    "                     .merge(df_meta, on = 'track_id', how = 'inner'))\n",
    "    \n",
    "    df_union['clear_text'] = df_union['text'].apply(lambda x: clear_text(r'[^а-яА-Я]', x))\n",
    "    df_union.loc[(df_union['clear_text'] != '') &\n",
    "             (df_union['language'].isna()), 'language'] = 'RU' \n",
    "    df_union = df_union.drop('clear_text', axis=1)\n",
    "    \n",
    "    return df_union.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05230208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2823, 11)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union = get_united_df(PATH_COVERS, PATH_LYRICS, PATH_META)\n",
    "df_union.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34f2b8",
   "metadata": {},
   "source": [
    "У нас получился датасет из 2823 строк, в котором есть все требуемые данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee43fba",
   "metadata": {},
   "source": [
    "Теперь нам нужно создать столбец в котором будут указаны все каверы / оригиналы для конкретного original_track_id и посчитать их количество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b92797b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_covers_column(df: pd.DataFrame, count_cover=True) -> pd.DataFrame:\n",
    "    df_new = df.copy(deep=True)\n",
    "    df_group = df.groupby('original_track_id', as_index= False ).agg({'track_id': ' '. join})\n",
    "    df_group = df_group.rename(columns = {'track_id': 'cover_list'})\n",
    "    df_group['cover_list'] = df_group['cover_list'].str.split()\n",
    "    \n",
    "    # присоединим список с датасетом и удалим из списка сам трек\n",
    "    df_new = df_new.merge(df_group, on = 'original_track_id', how='inner')\n",
    "#     df_new['cover_list'] = df_new.apply(lambda x: list(set(x['cover_list']) ^ set(x['track_id'])), axis=1)\n",
    "    \n",
    "    if count_cover:\n",
    "        df_new['cover_count'] = df_new['cover_list'].apply(lambda x: len(x))\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfa1982f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_track_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_remake_type</th>\n",
       "      <th>lyricId</th>\n",
       "      <th>text</th>\n",
       "      <th>dttm</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>isrc</th>\n",
       "      <th>genres</th>\n",
       "      <th>duration</th>\n",
       "      <th>cover_list</th>\n",
       "      <th>cover_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>ORIGINAL</td>\n",
       "      <td>260f21d9f48e8de874a6e844159ddf28</td>\n",
       "      <td>Left a good job in the city\\nWorkin' for the m...</td>\n",
       "      <td>2009-11-11 21:00:00</td>\n",
       "      <td>Proud Mary</td>\n",
       "      <td>EN</td>\n",
       "      <td>USFI86900049</td>\n",
       "      <td>[ROCK, ALLROCK]</td>\n",
       "      <td>187220.0</td>\n",
       "      <td>[eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>14cd5aac84c43bf6830c8276c05ee2f8</td>\n",
       "      <td>COVER</td>\n",
       "      <td>dee9f62b6793743f535dc38c3dbd9424</td>\n",
       "      <td>Left a good job down in the city\\nWorkin' for ...</td>\n",
       "      <td>2010-01-31 21:00:00</td>\n",
       "      <td>Proud Mary</td>\n",
       "      <td>EN</td>\n",
       "      <td>FRZ040600166</td>\n",
       "      <td>[ROCK, ALLROCK]</td>\n",
       "      <td>395460.0</td>\n",
       "      <td>[eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>c99604698f81b2454389e8e3b6d3520b</td>\n",
       "      <td>COVER</td>\n",
       "      <td>d31d606bc0221f04551e2b04737bd24f</td>\n",
       "      <td>You know, every now and then I think you might...</td>\n",
       "      <td>2014-04-16 20:00:00</td>\n",
       "      <td>Proud Mary</td>\n",
       "      <td>EN</td>\n",
       "      <td>GBAYE9300862</td>\n",
       "      <td>[POP, RNB]</td>\n",
       "      <td>327390.0</td>\n",
       "      <td>[eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>70ce45ec4414b7993d98718995456668</td>\n",
       "      <td>COVER</td>\n",
       "      <td>86390e840a3342d5c7431daca79d278e</td>\n",
       "      <td>Y' know, Every now and then\\nI think You might...</td>\n",
       "      <td>2012-12-29 22:56:50</td>\n",
       "      <td>Proud Mary</td>\n",
       "      <td>EN</td>\n",
       "      <td>FR6V81426499</td>\n",
       "      <td>[ELECTRONICS, LOUNGE]</td>\n",
       "      <td>190030.0</td>\n",
       "      <td>[eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eeb69a3cb92300456b6a5f4162093851</td>\n",
       "      <td>e58d2c71ff16648513a9c727281fb474</td>\n",
       "      <td>COVER</td>\n",
       "      <td>3efff45e3508e1a7fcd5a97bbb1de8f5</td>\n",
       "      <td>Left a good job in the city\\nWorkin' for the m...</td>\n",
       "      <td>2013-11-16 06:24:08</td>\n",
       "      <td>Proud Mary</td>\n",
       "      <td>EN</td>\n",
       "      <td>FR6V80083191</td>\n",
       "      <td>[ALLROCK, RNR]</td>\n",
       "      <td>155350.0</td>\n",
       "      <td>[eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  original_track_id                          track_id   \n",
       "0  eeb69a3cb92300456b6a5f4162093851  eeb69a3cb92300456b6a5f4162093851  \\\n",
       "1  eeb69a3cb92300456b6a5f4162093851  14cd5aac84c43bf6830c8276c05ee2f8   \n",
       "2  eeb69a3cb92300456b6a5f4162093851  c99604698f81b2454389e8e3b6d3520b   \n",
       "3  eeb69a3cb92300456b6a5f4162093851  70ce45ec4414b7993d98718995456668   \n",
       "4  eeb69a3cb92300456b6a5f4162093851  e58d2c71ff16648513a9c727281fb474   \n",
       "\n",
       "  track_remake_type                           lyricId   \n",
       "0          ORIGINAL  260f21d9f48e8de874a6e844159ddf28  \\\n",
       "1             COVER  dee9f62b6793743f535dc38c3dbd9424   \n",
       "2             COVER  d31d606bc0221f04551e2b04737bd24f   \n",
       "3             COVER  86390e840a3342d5c7431daca79d278e   \n",
       "4             COVER  3efff45e3508e1a7fcd5a97bbb1de8f5   \n",
       "\n",
       "                                                text                dttm   \n",
       "0  Left a good job in the city\\nWorkin' for the m... 2009-11-11 21:00:00  \\\n",
       "1  Left a good job down in the city\\nWorkin' for ... 2010-01-31 21:00:00   \n",
       "2  You know, every now and then I think you might... 2014-04-16 20:00:00   \n",
       "3  Y' know, Every now and then\\nI think You might... 2012-12-29 22:56:50   \n",
       "4  Left a good job in the city\\nWorkin' for the m... 2013-11-16 06:24:08   \n",
       "\n",
       "        title language          isrc                 genres  duration   \n",
       "0  Proud Mary       EN  USFI86900049        [ROCK, ALLROCK]  187220.0  \\\n",
       "1  Proud Mary       EN  FRZ040600166        [ROCK, ALLROCK]  395460.0   \n",
       "2  Proud Mary       EN  GBAYE9300862             [POP, RNB]  327390.0   \n",
       "3  Proud Mary       EN  FR6V81426499  [ELECTRONICS, LOUNGE]  190030.0   \n",
       "4  Proud Mary       EN  FR6V80083191         [ALLROCK, RNR]  155350.0   \n",
       "\n",
       "                                          cover_list  cover_count  \n",
       "0  [eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...           14  \n",
       "1  [eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...           14  \n",
       "2  [eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...           14  \n",
       "3  [eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...           14  \n",
       "4  [eeb69a3cb92300456b6a5f4162093851, 14cd5aac84c...           14  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union = make_covers_column(df_union)\n",
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a64d1cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['eeb69a3cb92300456b6a5f4162093851', '14cd5aac84c43bf6830c8276c05ee2f8', 'c99604698f81b2454389e8e3b6d3520b', '70ce45ec4414b7993d98718995456668', 'e58d2c71ff16648513a9c727281fb474', '08dd2a07ac97c3fa4fa199acc5ac1e80', 'b5f9882ee2f5ba91089e3fcaf47ed061', 'a1969006135564d52455fdeb509f1a4e', 'b3728c3e3ba2282e328eba4f6ce787f6', '0c0442e572f4dbe1f20092c4213aa776', 'e3fa439cac2293992eb337189e73acbb', 'ecc749ddb382d52c1161e517d878d8d6', 'b9564f7c8ee984ae62d783b9b106e41a', 'fb9c2a1609c3cd925c7360340476ed4b']),\n",
       "       list(['eeb69a3cb92300456b6a5f4162093851', '14cd5aac84c43bf6830c8276c05ee2f8', 'c99604698f81b2454389e8e3b6d3520b', '70ce45ec4414b7993d98718995456668', 'e58d2c71ff16648513a9c727281fb474', '08dd2a07ac97c3fa4fa199acc5ac1e80', 'b5f9882ee2f5ba91089e3fcaf47ed061', 'a1969006135564d52455fdeb509f1a4e', 'b3728c3e3ba2282e328eba4f6ce787f6', '0c0442e572f4dbe1f20092c4213aa776', 'e3fa439cac2293992eb337189e73acbb', 'ecc749ddb382d52c1161e517d878d8d6', 'b9564f7c8ee984ae62d783b9b106e41a', 'fb9c2a1609c3cd925c7360340476ed4b']),\n",
       "       list(['eeb69a3cb92300456b6a5f4162093851', '14cd5aac84c43bf6830c8276c05ee2f8', 'c99604698f81b2454389e8e3b6d3520b', '70ce45ec4414b7993d98718995456668', 'e58d2c71ff16648513a9c727281fb474', '08dd2a07ac97c3fa4fa199acc5ac1e80', 'b5f9882ee2f5ba91089e3fcaf47ed061', 'a1969006135564d52455fdeb509f1a4e', 'b3728c3e3ba2282e328eba4f6ce787f6', '0c0442e572f4dbe1f20092c4213aa776', 'e3fa439cac2293992eb337189e73acbb', 'ecc749ddb382d52c1161e517d878d8d6', 'b9564f7c8ee984ae62d783b9b106e41a', 'fb9c2a1609c3cd925c7360340476ed4b']),\n",
       "       ..., list(['dd3b864285b4cdcd2363985ec12bbcfa']),\n",
       "       list(['1dd3cbe5aafe4e3fe246abbed7850c01']),\n",
       "       list(['6701ac2dc589eb75e571d250df71bfd6'])], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union['cover_list'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d0c06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdab53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3e098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e64d3b1",
   "metadata": {},
   "source": [
    "Разделим датасет на тренировочную, тестовую и валидационную выборки. Стрритификацию будем проводить по столбцу cover_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_union,\n",
    "                                     random_state=RANDOM_STATE,\n",
    "                                     test_size=0.3,\n",
    "                                     stratify=df_union['cover_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a532d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, df_valid = train_test_split(df_test,\n",
    "                                     random_state=RANDOM_STATE,\n",
    "                                     test_size=0.5,\n",
    "                                     stratify=df_test['cover_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c223d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb512cd4",
   "metadata": {},
   "source": [
    "Теперь удалим созданные столбцы и пересоздадим их заново (тренировочная выборка не должна ничего знать о тестовой и валидационной, а из тестовой и валидационной выборки нас будут интересовать количество каверов из трейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['cover_list', 'cover_count'], axis=1)\n",
    "df_test = df_test.drop(['cover_list', 'cover_count'], axis=1)\n",
    "df_valid = df_valid.drop(['cover_list', 'cover_count'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4f0f5",
   "metadata": {},
   "source": [
    "Получим для "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bdfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
